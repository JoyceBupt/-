# **恶意软件图像：可视化与自动分类**

> L. Nataraj, S. Karthikeyan
>
> G. Jacob
>
> B. S. Manjunath

**摘要** 我们提出了一种简单但是有效的方法，通过使用图像处理技术来可视化和分类恶意软件。通过将恶意软件的二进制文件以灰度图像显示，发现同一恶意软件家族的图像在布局和纹理上表现出很大的相似性。受这一视觉相似性激励，我们提出了一种使用标准图像特征的分类方法。这种方法无需反汇编或代码执行。初步实验结果显示，我们在9458个样本和25个恶意软件家族的数据集中达到了98%的分类准确率。此技术还能有效应对混淆技术，比如区段加密。

------

## **1. 简介** 

传统的面向分析恶意软件的方法涉及从恶意软件中提取二进制签名，构成他们的指纹。由于恶意软件数量激增，每年新发布的签名数量指数级增长（在[1]中，Symantec 报告显示，在2009年有2,895,802个新签名，而2008年仅有169,323个）。
其他分析恶意软件方法包括静态代码分析和动态代码分析。静态分析通过反汇编代码与探索可执行文件的控制流来查找恶意模式。另一方面，动态分析通过在虚拟环境中执行代码，同时生成一个基于执行轨迹的行为报告描述可执行文件。这两种技术各有优缺点。静态分析提供了最全面的覆盖，但通常会受到代码混淆的影响。在分析之前，必须对可执行文件进行解包和解密，即便如此，分析仍可能因复杂性问题而受到阻碍。动态分析则更加高效，不需要对可执行文件进行解包或解密。然而，它耗时且资源消耗较大，从而引发了可扩展性问题。此外，一些恶意行为可能未被观察到，因为环境未能满足触发条件。

在本文中，我们采用了一种完全不同且新颖的方法来描述和分析恶意软件。从广义上讲，恶意软件可执行文件可以表示为一个由0和1组成的二进制字符串。该向量可以重构为一个矩阵并以图像形式展示。我们观察到，属于同一恶意软件家族的图像在纹理上表现出显著的视觉相似性。这可能是由于重用代码来创建新恶意软件变种的常见做法所致。在第3节中，我们讨论了将恶意软件二进制文件表示为图像的过程。在第4节中，我们将恶意软件分类问题视为图像分类问题。现有的分类技术需要反汇编或执行代码，而我们的方法不需要这些步骤，却在性能上仍然表现出显著的改进。此外，它对流行的混淆技术（如段加密）也具有一定的弹性。这个自动分类技术对于每天接收大量恶意软件的防病毒公司和安全研究人员来说非常有价值。

本文剩余部分的结构如下：在第2节中，我们讨论了与恶意软件可视化和分类相关的工作。在第3节和第4节中，我们描述了使用图像可视化恶意软件并自动分类的方法。第5节中详细介绍了实验。第6节中我们讨论了该方法的局限性，并在第7节中进行了总结。

------

## **2. 相关工作** 

许多工具，例如文本编辑器和二进制编辑器，都可以可视化和操作二进制数据。最近，已经出现了几种基于GUI（图形用户界面）的工具，可以方便地比较文件。然而，关于恶意软件可视化的研究还相对有限。在[3]中，Yoo使用自组织映射（self-organizing maps）来检测和可视化可执行文件中的恶意代码。在[4]中，Quist和Liebrock开发了一个用于逆向工程的可视化框架。他们通过节点-链接可视化识别功能区域并进行去混淆处理，其中节点表示地址，链接表示地址之间的状态转换。在[5]中，Trinius等人使用树状图（treemaps）显示操作的分布，并使用线程图（thread graphs）显示操作的顺序。在[6]中，Goodall等人开发了一个可视化分析环境，帮助软件开发人员更好地理解代码。他们还展示了如何在该环境中可视化软件中的漏洞。

虽然在将恶意软件视为数字图像方面的研究较少，但Conti等人[8,9]将原始二进制数据（如文本、C++数据结构、图像数据、音频数据）可视化为图像。在[7]中，Conti等人展示了他们可以使用统计特征自动分类不同的二进制片段。然而，他们的分析仅限于识别原始二进制片段，而不是恶意软件。本研究采用了类似的方法，将恶意软件表示为灰度图像。

多种技术已经被提出，用于恶意软件的聚类和分类，这些技术包括静态分析[13-19]和动态分析[20-24]。我们将回顾一些专门针对恶意软件分类的论文。在[24]中，Rieck等人基于恶意软件行为分析的特征将恶意软件根据其家族进行分类。他们使用了一个由防病毒软件标记的10,072个恶意软件样本的数据集，并将该数据集分为14个恶意软件家族。然后他们在一个沙盒环境中监控所有恶意软件的行为，生成了一个行为报告。根据报告中的某些特定字符串的频率，他们为每个恶意软件生成了一个特征向量。随后，他们使用支持向量机（Support Vector Machine, SVM）对14个家族的特征进行训练和测试，并报告了88%的平均分类准确率。与[24]相比，Tian等人[16]使用了一个非常简单的特征——程序的长度，来分类7种不同类型的特洛伊木马，并获得了88%的平均准确率。然而，他们的分析仅在721个文件上进行。在[17,18]中，同一作者通过使用恶意软件中的可打印字符串信息改进了上述技术。他们在包含13个家族的1521个恶意软件上评估了他们的方法，并报告了98.8%的分类准确率。在[20]中，Park等人基于行为图中检测到的最大公共子图对恶意软件进行分类。他们在包含300个恶意软件和6个家族的集合上展示了他们的结果。

关于相关工作，我们的分类方法不需要对实际恶意软件代码进行反汇编或执行。此外，分类中使用的图像纹理在应对混淆技术，特别是加密方面提供了更具弹性的特征。最后，我们在包含9458个恶意软件的25个家族的数据集上评估了我们的方法。评估结果表明，我们的方法在较低的计算成本下提供了与现有方法相似的精度。

------

## **3. 可视化** 

![image-20240919222323468](https://joyce-mkm.oss-cn-beijing.aliyuncs.com/img_for_typora/image-20240919222323468.png)

给定的恶意软件二进制文件被读取为8位无符号整数的向量，然后组织成二维数组。这可以被可视化为一个灰度图像，范围为[0,255]（0表示黑色，255表示白色）。图像的宽度是固定的，而高度则根据文件大小变化（如图1）。表1根据经验观察给出了不同文件大小对应的推荐图像宽度。

![image-20240919221938260](https://joyce-mkm.oss-cn-beijing.aliyuncs.com/img_for_typora/image-20240919221938260.png)

<center><strong>
    Fig.1 Visualizing Malware as an Image
</center>


图2展示了一个常见的木马下载器Dontovo A的示例图像，该木马下载并执行任意文件[26]。有趣的是，在许多情况下，如图2所示，恶意软件的不同部分（二进制片段）表现出不同的图像纹理。在[9]中可以找到各种原始二进制片段的详细分类及其作为灰度图像的可视化。

![image-20240919222008280](https://joyce-mkm.oss-cn-beijing.aliyuncs.com/img_for_typora/image-20240919222008280.png)

<center><strong>
    Fig. 2 Various Sections of Trojan: Dontovo.A
</center>


.text段包含可执行代码。从图中可以看到，.text段的第一部分包含纹理精细的代码，其余部分被零（黑色）填充，表示该部分末尾的零填充。接下来的.data段包含未初始化的代码（黑色块）和已初始化的数据（精细纹理）。最后一部分是.rsrc段，它包含模块的所有资源，这些资源可能还包括应用程序使用的图标。

------

## **4. 恶意软件分类** 

图3展示了来自两个不同恶意软件家族的示例。从中可以通过经验观察到，同一恶意软件家族中的不同样本图像在视觉上表现出相似性，而与属于不同家族的样本相比则存在明显的差异。如前所述，这种情况可能是由于重用旧的恶意软件二进制文件来创建新变种所致。恶意软件图像的视觉相似性促使我们考虑使用计算机视觉技术来进行恶意软件分类，在基于图像的分类中，计算机视觉技术已被广泛研究。特定恶意软件家族的图像可以在图7中看到。正如图7所示，各个恶意软件家族具有不同的视觉特征。

![image-20240919222407903](https://joyce-mkm.oss-cn-beijing.aliyuncs.com/img_for_typora/image-20240919222407903.png)

<center>
    <strong>图3中，第一行的图像是属于Fakerean家族的三个恶意软件实例的图像[26]，而第二行的图像则属于Dontovo.A家族[26]。</strong>
</center>


### **4.1 图像纹理** 

关于视觉纹理，并没有一个公认的定义，但它通常与图4中所示的（重复）模式相关联[27]。纹理研究的三个主要领域是纹理分类、纹理分析和纹理合成。纹理分类关注的是识别图像中各种具有均匀纹理的区域。识别不同纹理区域的边界是纹理分割的主要目标。纹理合成方法用于合成纹理图像，常用于计算机图形学中。

![image-20240919222439744](https://joyce-mkm.oss-cn-beijing.aliyuncs.com/img_for_typora/image-20240919222439744.png)

<center><strong>
    Fig. 4 Examples of two texture images from Brodatz’s album [28]
</center>


纹理分析是计算机视觉中一个重要的研究领域。大多数表面都表现出一定程度的纹理。纹理分析被应用于许多领域，包括医学图像分析、遥感和文档图像处理。前面图2和图3展示的恶意软件图像，虽然并不完全是重复的模式，但展示了大量的“纹理”，这些信息可以被利用于自动分类。

### **4.2 特征向量和分类器**

已经提出了多种特征用于分析纹理。最常见的纹理分析方法之一是分析纹理块的频率内容。标准方法将频率域分为环形区域（尺度）和楔形区域（方向），并在这些区域中计算特征。心理物理学研究表明，人眼通过将图像分解为频率和方向成分来分析纹理。一个流行的计算方法是使用Gabor滤波器。二维Gabor函数由特定频率和方向的正弦平面组成，并由高斯包络调制。Gabor滤波器是一种对频率和方向敏感的滤波器。通过改变频率和方向，我们得到了一组Gabor滤波器。图像通过这组滤波器后，会生成多个经过滤波的图像，从中提取基于纹理的特征。一个这样的特征是通过计算变换值与小窗口内均值的绝对平均偏差得到的。使用Gabor滤波器的纹理特征已成功应用于纹理分割和分类。

在本文中，我们使用类似的特征来表征和分类恶意软件。为了计算纹理特征，我们使用GIST [11],[12]，它基于图像的小波分解。这一特征在场景分类和物体分类中非常成功。每个图像位置都由不同方向和尺度的滤波器输出值表示。我们使用一个具有8个方向和4个尺度的可控金字塔应用于图像。图像的局部表示由以下公式给出：$V^L(x)=\{V_k(x)\}_{k=1,N}$，其中N=20是子频带的数量。

为了在保留局部信息的同时捕捉图像的全局属性，我们计算局部特征的幅度在大空间区域上的平均值：

$$
m(x) = \sum{|v(x')|w(x'-x)} \tag1
$$
其中w(x)是平均窗口。最终的表示被下采样为具有MxM像素的空间分辨率（此处我们使用M=4）。因此，m的大小为$M\times M\times N =320$，这是我们使用的GIST特征的维度。关于GIST特征的更详细解释可以参见[12]。

我们使用欧几里得距离的k近邻（k-nearest neighbors, KNN）分类器进行分类。在所有测试中，我们使用10倍交叉验证。在每次测试中，随机选择一个类别的子集用于训练和测试。在每次迭代中，随机选择90%的数据用于训练，10%的数据用于测试。因此，给定的测试数据会被分类到其k个最近邻的众数类别中。

------

## **5. 实验** 

在本节中，我们所研究的恶意软件是提交给Anubis分析系统[2]的恶意软件可执行文件。因此，测试的样本是可以在“野外”找到的最新恶意软件。为了获取测试的真实情况（ground truth），我们使用Microsoft Security Essentials提供的标签将它们分类为不同的恶意软件家族。

### **5.1 假设验证**

为了验证恶意软件家族在视觉上表现出某些相似性的假设，我们首先选择了一个较小的数据集，该数据集由8个恶意软件家族组成，共包含1713个恶意软件图像。我们查看了这些图像的缩略图，并验证这些属于同一家族的图像确实是相似的。我们为这些图像的每一张计算了GIST图像特征。平均每张图像计算GIST特征的时间为54毫秒。高维的GIST特征随后被投影到低维空间以便进行可视化/分析[10]。如图5所示，家族Allaple.A、VB.AT、Wintrim.BX、Yuner.A和Fakerean的特征点很好地分离开了。然而，家族Instantaccess、Obfuscator.AD和Skintrim.N之间似乎存在混淆。这在它们的灰度图像可视化中也可以看出，如图7所示，它们在视觉上对人眼看起来也非常相似。然而，这些家族依然能够通过我们的分类方法准确分类。我们使用k=3的k近邻分类器（k-nearest neighbor, KNN），通过10倍交叉验证进行分类，并在10次测试中获得了0.9993的分类率，标准差为0.0019。混淆矩阵如表2所示。在1到10的k值变化中，尽管k=3取得了最佳准确率，但结果都相似。在加入123个来自Win32系统文件和应用程序的良性可执行文件后，我们重复了这些测试。我们使用的数据集可以从[30]中获取。在新数据集上，经过10倍交叉验证后，分类率为0.9929，标准差为0.002。

![image-20240919222919889](https://joyce-mkm.oss-cn-beijing.aliyuncs.com/img_for_typora/image-20240919222919889.png)

<center><strong>
    Fig.5 GIST Features projected in lower dimensions using multidimensional scaling [10]
</center>


![image-20240919222911855](https://joyce-mkm.oss-cn-beijing.aliyuncs.com/img_for_typora/image-20240919222911855.png)

在本实验中，恶意软件家族包括335个Instantaccess (A)、485个Yuner.A (B)、111个Obfuscator.AD (C)、80个Skintrim.N (D)、298个Fakerean (E)、88个Wintrim.BX (F)、97个VB.AT (G)和219个Allaple.A (H)。

---

# My Work

> 具体代码和运行结果可在`knn.ipynb`及`cnn.ipynb`文件中看到

* 分类准确率

**KNN**: 训练集上的分类准确率为**99.32%**，10折交叉验证的准确率为**99.46%**，标准差为0.0068，模型具有很好的稳定性。

**CNN**: 测试集上的分类准确率为**99.55%**，比KNN略高。

从准确率来看，**CNN**在测试集上的表现比KNN略优，但差距并不大。CNN的优势可能得益于其更强的特征提取能力，而KNN相对简单，依赖于简单欧式距离度量。

* 混淆矩阵对比

KNN混淆矩阵，大多数类的分类准确度较高，除恶意软件家族Fakerean表现稍差和VB.AT准确率略低外，其他均有接近100%的准确率。错误分类中，Fakerean有**5.56%**的样本被误分类为Wintrim.BX；VB.AT有**3.6%**的样本被误分类为Allaple.A。

CNN混淆矩阵：仅恶意软件家族Fakerean表现较差，分别各有6%的样本被误分类为Allaple.A和Wintrim.BX，其他都达到100%准确率。

　　<table style="border:none;text-align:center;width:auto;margin: 0 auto;">
	<tbody>
		<tr>
			<td style="padding: 6px">
                <img src="https://joyce-mkm.oss-cn-beijing.aliyuncs.com/img_for_typora/image-20240920185845921.png" >
            </td>
            <td>
                <img src="https://joyce-mkm.oss-cn-beijing.aliyuncs.com/img_for_typora/image-20240920185836015.png" >
            </td>
		</tr>
        <tr>
            <td><strong>图 1  KNN</strong></td>
            <td><strong>图 2  CNN</strong></td>
        </tr>
	</tbody>
</table>

* 模型优劣势对比

| 模型优劣 | KNN                                                          | CNN                                                          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 优势     | 简单易实现（sklearn库直接用即可），训练过程不涉及复杂的参数优化。<br />对于多数类别，KNN的分类表现非常好，并且交叉验证标准差较小，稳定性较强。 | CNN擅长处理图像数据，能够通过卷积层自动学习图像特征，因此在准确率上表现略优。 |
| 劣势     | 对Fakerean和VB.AT的误分类率较高，可能是由于KNN对类间距离的敏感性，在数据分布上无法很好地区分某些相似类别。<br />KNN的分类效果依赖于数据的规模和维度，随着数据量增大，计算量增加，性能可能下降。 | CNN需要更复杂的模型训练，计算开销较大，卷积层的训练需更长时间。 <br />Fakerean家族的分类准确率较低，误分类较其他类别的情况较为严重。 |

更进一步的，我认为也是**特征提取技术**与**图像分类技术**之间的一个重要区别（由于我数据处理手段还是比较粗糙，因此可能本实验结果中对比不是非常明显）。前者通过人为设定的规则提取图像特征，而后者（如CNN）通过深度学习模型自动从图像数据中学习和提取特征。

> **GIST特征**是特征提取的一种方法，旨在提取图像的整体布局信息，主要用于场景识别和纹理分析。通过类似Gabor滤波器的技术，可以提取纹理信息、方向和频率等特征。
>
> 常见的图像分类技术包括：**卷积神经网络（CNN）**，它直接处理原始图像的像素信息，通过自学习从图像中提取有效的特征，而无需像GIST这样的手动特征提取方法。

| **特征提取技术**                           | **图像分类技术（CNN）**                          |
| ------------------------------------------ | ------------------------------------------------ |
| 人工定义的特征（如GIST、HOG、SIFT）        | 自动从数据中学习特征                             |
| 需要手动设计特征提取方法                   | 不需要特征设计，自动学习不同层次的特征           |
| 通常需要特征维度降低，以减少计算量         | 直接处理原始图像，通过层次化结构逐步提取高维特征 |
| 适用于简单图像场景或纹理分析任务           | 适用于复杂的图像分类任务，具有更好的泛化能力     |
| 特征提取后可结合传统分类器（如KNN、SVM等） | 端到端训练，不需要额外的特征提取步骤             |
